python ../preprocess_tokenized_data.py --trainfile ../babylm_data/tokenized/parsed_tokenized_train.txt --valfile ../babylm_data/tokenized/parsed_tokenized_dev.txt  --testfile ../babylm_data/tokenized/parsed_tokenized_test.txt --outputfile ../babylm_data/tokenized/babylm_final_dataset_64 --vocabfile ../tokenizers/babylm/vocab.json --vocab_file_type json --vocabminfreq 0 --lowercase 0 --replace_num 0 --batchsize 64