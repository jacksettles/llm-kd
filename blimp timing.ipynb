{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abef3352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import os\n",
    "import glob\n",
    "from tokenizers import ByteLevelBPETokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from gpt2_model import GPT, generate_square_subsequent_mask\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba01b244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(\"Cuda is available. Using GPU.\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"Cuda is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6908783",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"saved_models/bllip/distilled/distilled_bllip_ltg_gpt2.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b697f21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29436145",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probs(sentence, model, tokenizer):\n",
    "    with torch.no_grad():\n",
    "        tokens = tokenizer.encode(sentence).ids\n",
    "\n",
    "        # Add BOS and EOS tokens to match training regimen\n",
    "        tokens.insert(0, 0)\n",
    "        tokens.append(2)\n",
    "\n",
    "        # Add batch dimension and move to device\n",
    "        tokens = torch.tensor(tokens, dtype=torch.long).unsqueeze(0).to(device)\n",
    "        model.to(device)\n",
    "        inputs = tokens[:, :-1]\n",
    "        labels = tokens[:, 1:]\n",
    "\n",
    "        mask = generate_square_subsequent_mask(size=inputs.size(1), device=device)\n",
    "        logits = model(input_ids=inputs, attention_mask=mask)\n",
    "        log_probs_word = F.log_softmax(logits, dim=-1)\n",
    "\n",
    "        # Add dimension to labels\n",
    "        # Then gather lob probs in log_probs_word based on values in labels\n",
    "        # Then ditch the last dimension and sum total log_probs\n",
    "        gathered_log_probs = torch.gather(log_probs_word, 2, labels.unsqueeze(2)).squeeze(2).sum(1)\n",
    "        return gathered_log_probs\n",
    "    \n",
    "def run_test_suite(model, files, tokenizer, seed=42):\n",
    "    torch.manual_seed(seed)\n",
    "    score_dict = {}\n",
    "    for file in files:\n",
    "        with jsonlines.open(file) as reader:\n",
    "            data = [obj for obj in reader]\n",
    "        total_sents = len(data)\n",
    "        total_correct = 0\n",
    "        for test in data:\n",
    "            good_sentence = \" \" + test['sentence_good']\n",
    "            bad_sentence = \" \" + test['sentence_bad']\n",
    "\n",
    "            good_probs = get_probs(good_sentence, model, tokenizer)\n",
    "            bad_probs = get_probs(bad_sentence, model, tokenizer)\n",
    "\n",
    "            if good_probs > bad_probs:\n",
    "                total_correct += 1\n",
    "        score = (total_correct / total_sents)*100\n",
    "        score_dict[file] = score\n",
    "    return score_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32d18869",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = ByteLevelBPETokenizer('tokenizers/rnng/vocab.json', 'tokenizers/rnng/merges.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba2655e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = ['blimp_data/sentential_negation_npi_scope.jsonl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "42fcfb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = run_test_suite(model, files, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17253304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1c623a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = \"blimp_data/*.jsonl\"\n",
    "files = glob.glob(pattern, recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff21cf03",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_terms = []\n",
    "for file in files:\n",
    "    with jsonlines.open(file) as reader:\n",
    "        data = [obj for obj in reader]\n",
    "    for row in data:\n",
    "        all_terms.append(row['linguistics_term'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e2d6409",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'island_effects': 8000,\n",
       "         'argument_structure': 7000,\n",
       "         'quantifiers': 4000,\n",
       "         'determiner_noun_agreement': 8000,\n",
       "         'control_raising': 5000,\n",
       "         'subject_verb_agreement': 6000,\n",
       "         's-selection': 2000,\n",
       "         'filler_gap_dependency': 7000,\n",
       "         'binding': 7000,\n",
       "         'npi_licensing': 7000,\n",
       "         'anaphor_agreement': 2000,\n",
       "         'irregular_forms': 2000,\n",
       "         'ellipsis': 2000})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(all_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e1780c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
