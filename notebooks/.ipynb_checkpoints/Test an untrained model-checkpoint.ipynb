{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2116c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Dataset\n",
    "from models import RNNG, RNNLM\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4277467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available. Using GPU.\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    # CUDA is available, you can proceed to use it\n",
    "    device = torch.device('cuda')\n",
    "    print('CUDA is available. Using GPU.')\n",
    "else:\n",
    "    # CUDA is not available, use CPU\n",
    "    device = torch.device('cpu')\n",
    "    print('CUDA is not available. Using CPU.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecf44d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Dataset('full_data/full-ptb-train.pkl')\n",
    "test_data = Dataset('full_data/full-ptb-test.pkl')\n",
    "val_data = Dataset('full_data/full-ptb-val.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e30140dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e565bf14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNG(\n",
       "  (emb): Embedding(11008, 650)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (stack_rnn): SeqLSTM(\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=1300, out_features=2600, bias=True)\n",
       "      (1): Linear(in_features=1300, out_features=2600, bias=True)\n",
       "    )\n",
       "    (dropout_layer): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (tree_rnn): TreeLSTM(\n",
       "    (linear): Linear(in_features=1300, out_features=3250, bias=True)\n",
       "  )\n",
       "  (vocab_mlp): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=650, out_features=11008, bias=True)\n",
       "  )\n",
       "  (q_binary): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (action_mlp_p): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=650, out_features=1, bias=True)\n",
       "  )\n",
       "  (q_leaf_rnn): LSTM(650, 256, batch_first=True, bidirectional=True)\n",
       "  (q_crf): ConstituencyTreeCRF()\n",
       "  (q_pos_emb): Embedding(250, 650)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_rnng = RNNG(\n",
    "    vocab=11008,\n",
    "    w_dim=650,           # Dimensionality of word embeddings\n",
    "    h_dim=650,           # Dimensionality of hidden states\n",
    "    q_dim=256,           # Dimensionality of 'q' vector\n",
    "    num_layers=2, # Number of layers\n",
    "    dropout=0.5,       # Dropout rate\n",
    "    max_len=250\n",
    ")\n",
    "raw_rnng.cuda()\n",
    "raw_rnng.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d51693a",
   "metadata": {},
   "source": [
    "# Now try a trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02e7f985",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_data = torch.load('rnng.pt')\n",
    "model_args = loaded_data['args']\n",
    "model_state_dict = loaded_data['model'].state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0058eb5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNNG(\n",
       "  (emb): Embedding(11008, 650)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (stack_rnn): SeqLSTM(\n",
       "    (linears): ModuleList(\n",
       "      (0): Linear(in_features=1300, out_features=2600, bias=True)\n",
       "      (1): Linear(in_features=1300, out_features=2600, bias=True)\n",
       "    )\n",
       "    (dropout_layer): Dropout(p=0.5, inplace=False)\n",
       "  )\n",
       "  (tree_rnn): TreeLSTM(\n",
       "    (linear): Linear(in_features=1300, out_features=3250, bias=True)\n",
       "  )\n",
       "  (vocab_mlp): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=650, out_features=11008, bias=True)\n",
       "  )\n",
       "  (q_binary): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (action_mlp_p): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=650, out_features=1, bias=True)\n",
       "  )\n",
       "  (q_leaf_rnn): LSTM(650, 256, batch_first=True, bidirectional=True)\n",
       "  (q_crf): ConstituencyTreeCRF()\n",
       "  (q_pos_emb): Embedding(250, 650)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnng = RNNG(\n",
    "    vocab=len(loaded_data['word2idx']),\n",
    "    w_dim=model_args['w_dim'],           # Dimensionality of word embeddings\n",
    "    h_dim=model_args['h_dim'],           # Dimensionality of hidden states\n",
    "    q_dim=model_args['q_dim'],           # Dimensionality of 'q' vector\n",
    "    num_layers=model_args['num_layers'], # Number of layers\n",
    "    dropout=model_args['dropout'],       # Dropout rate\n",
    "    max_len=250\n",
    ")\n",
    "rnng.load_state_dict(model_state_dict)\n",
    "rnng.eval()\n",
    "rnng.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dce666f",
   "metadata": {},
   "source": [
    "# Set up a test suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e92c844f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(model, dataset):\n",
    "    sentences = []\n",
    "    vocab_dict = dataset.idx2word\n",
    "    model.cuda()\n",
    "    rand_idx = np.random.randint(len(dataset))\n",
    "    tensor, _, _, _, _, _, _ = dataset[rand_idx]\n",
    "    tensor = tensor.cuda()\n",
    "    sent_length = tensor.size(1)\n",
    "    cutoff = np.random.choice([1, 2, 3])\n",
    "    tensor = tensor[:, :5]\n",
    "    for row in tensor:\n",
    "        sentence = [vocab_dict[idx.item()] for idx in row if idx.item() in vocab_dict]\n",
    "        sentences.append(\" \".join(sentence))\n",
    "        \n",
    "    output = model(tensor)\n",
    "    _, max_idx = torch.max(output, 1)\n",
    "    \n",
    "    preds = []\n",
    "    for x in max_idx:\n",
    "        prediction = vocab_dict[x.item()]\n",
    "        preds.append(prediction)\n",
    "        \n",
    "    return sentences, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a277ae65",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents, preds = make_prediction(rnng, train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68121035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> As for the findings \t\t\t\tPREDICTION:  ,\n",
      "\n",
      "<s> But anti-abortionists oppose such \t\t\t\tPREDICTION:  ,\n",
      "\n",
      "<s> Fujitsu said 0 it \t\t\t\tPREDICTION:  ,\n",
      "\n",
      "<s> After troubled Heritage Media \t\t\t\tPREDICTION:  ,\n",
      "\n",
      "<s> Most of the picture \t\t\t\tPREDICTION:  are\n",
      "\n",
      "<s> Elisa Hollis launched a \t\t\t\tPREDICTION:  ,\n",
      "\n",
      "<s> Due to an editing \t\t\t\tPREDICTION:  ,\n",
      "\n",
      "<s> Mr. Gartner is editor \t\t\t\tPREDICTION:  said\n",
      "\n",
      "<s> The battle has turned \t\t\t\tPREDICTION:  has\n",
      "\n",
      "<s> As more managers pursue \t\t\t\tPREDICTION:  ,\n",
      "\n",
      "<s> * Take the traditional \t\t\t\tPREDICTION:  ,\n",
      "\n",
      "<s> The futures industry is \t\t\t\tPREDICTION:  has\n",
      "\n",
      "<s> In recent months , \t\t\t\tPREDICTION:  ,\n",
      "\n",
      "<s> `` If we have \t\t\t\tPREDICTION:  ,\n",
      "\n",
      "<s> -- The USIA said \t\t\t\tPREDICTION:  ,\n",
      "\n",
      "<s> Today , about $ \t\t\t\tPREDICTION:  </s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(sents)):\n",
    "    print(sents[i], \"\\t\\t\\t\\tPREDICTION: \", preds[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed9b974",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e381fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
